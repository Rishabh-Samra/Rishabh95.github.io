import numpy as np
import gym
import pyglet
import matplotlib.pyplot as plt
from gym import error,spaces, utils
from gym.utils import seeding
from gym.envs.registration import registry, register, make, spec
from gym.envs.classic_control import rendering

WORLD_PUDDLE = [4, 5, 6] 
puddle_rewards = [-1,-2,-3]                                                #Puddle penalties -1, -2, and -3
puddle_dict = {i:j for i,j in zip(WORLD_PUDDLE,puddle_rewards)}
class funap(gym.Env):
    metadata = {'render.modes': ['human']}
   

    def __init__(self,noise=0.1, terminal_reward=10.0, border_reward = 0.0, st_state=[6,7,11,12],confusion=0.1,rew1 =-1,rew2 = -2,rew3 = -3,p1 = [39,40,41,42,43,44,45,51,57,63,69,75,81,87,91,92,93,99,100,101,102,103],p2 = [52,53,54,55,56,64,68,76,78,79,80,88,89,90],p3 = [65,66,67,77],term_state = [133]):
        self.UP = 0
        self.RIGHT = 1
        self.DOWN = 2
        self.LEFT = 3      
        
        self.noise = noise
        self.terminal_reward = terminal_reward
        self.border_reward   = border_reward
        self.n_states = 1200*120
        
        self.termi_state = self.mapping(self.ind2cord(term_state))
        self.p1_states  = self.mapping(self.ind2cord(p1))
        self.p2_states = self.mapping(self.ind2cord(p2))
        self.p3_states = self.mapping(self.ind2cord(p3))                                          #list 12
        self.penalty1_states = self.coord2ind(self.mapping(self.ind2cord(p1)))
        self.penalty2_states = self.coord2ind(self.mapping(self.ind2cord(p2)))
        self.penalty3_states = self.coord2ind(self.mapping(self.ind2cord(p3)))
        self.terminal_state = self.coord2ind(self.termi_state)
        
        self.start_state = self.mapping(self.ind2cord(st_state)) 
        self.state = np.random.choice(self.coord2ind(self.start_state))
        
        self.rew1 = rew1
        self.rew2 = rew2
        self.rew3 = rew3
        self.p = 0.9
        self.p_ = (1 - self.p)/3
        self.absorbing_state = self.n_states - 1
        self.done = False
        self.reset()
        self.action_space = spaces.Discrete(4)
        self.observation_space = spaces.Discrete(self.n_states) # with absorbing state
        self.seed()
    
    
         
    def coord2ind(self, coord):
        a = []
        for i in range(len(coord)):
            [row, col] = coord[i]
            
            a.append(col*1200 + row +1)
        return a
      
    
    def ind2cord(self,ind):
        
        c = []
        for i in range(len(ind)):
            col = (ind[i] // 12)
            row = (ind[i] %12) - 1
        c.append([row,col])
            
        return c
        
        
    
    
    def ind2coord(self,ind):
        
        col = (ind // 1200)
        row = ind %1200 - 1
        return [row,col]
        
    def cord2ind(self, coord):
        
        [row, col] = coord
        
        c = (col*1200 + row +1)
        return c
        
    
    def mapping(self,coord):          #function for mapping between two puddle after blowing by 1000
        c = []
        for p in range(len(coord)):
            [x, y] = coord[p]
            
            for i in range(100*x-99,100*x):
                for j in range(10*y-9,10*y):
                    c.append([i,j])
        return(c)
            
              
        
    def get_reward(self,state):
        
        if (state in self.penalty1_states):
            reward = -1
        elif (state in self.penalty2_states):
            reward = -2
        elif (state in self.penalty3_states):
            reward = -3
        elif (state in self.terminal_state):
            reward = 10
        else:
            reward = 0
        return reward
    
    def next_state(self,state,action):
        
        [row,col] = self.ind2coord(self.state)
        if action == self.UP:
            row = max(row -1, 0)
        elif action == self.DOWN:
            row = min(row + 1, 1200 - 1)
        elif action == self.RIGHT:
            col = min(col + 1, 120 - 1)
        elif action == self.LEFT:
            col = max(col - 1, 0) 
        new_state = self.cord2ind([row, col])
        return new_state 
        
    def step(self, action):
    
        assert self.action_space.contains(action)

        if any(self.state == self.terminal_state):
            self.state = self.absorbing_state

            self.done = True
            info = None
            return self.state,self.get_reward(self.state), self.done,info
  
        if np.random.rand() < self.noise:
            action = self.action_space.sample()
                        
        new_state = self.next_state (self.state,action)
       
    #    if (new_state in self.penalty1_states):
     #       print('Found1')
      #  elif (new_state in self.penalty2_states):
      #      print('Found2')
    #    elif (new_state in self.penalty3_states):
     #       print('Found3')
      #  else:
       #     print('None')
            
            
        
        reward = self.get_reward(new_state)        
        self.state = new_state
        info = None
       
        return self.state,reward,self.done,info
        
      
    def reset(self):
        self.done = False
        self.state=np.random.choice(self.coord2ind(self.start_state))                    # starting states
        return self.state
      
    def seed(self):
        pass
        
        
     
    def render(self, mode ='human', close=False):
        p = []
        q = []
        r = []
        s = []
        t = []
        for i in range(len(self.penalty1_states)):
            p.append(self.ind2coord(self.penalty1_states[i]))
        
        
        for i in range(len(self.penalty2_states)):
            q.append(self.ind2coord(self.penalty2_states[i]))                  #element 1200
    
        for i in range(len(self.penalty3_states)):
            r.append(self.ind2coord(self.penalty3_states[i]))
    
        for i in range(len(self.terminal_state)):
            s.append(self.ind2coord(self.terminal_state[i]))
        for i in range(len(self.coord2ind(self.start_state))):
            t.append(self.ind2coord(self.coord2ind(self.start_state)[i]))
        
        
        rew = np.zeros((1200,120))
        
        for i in range(1200):
            for j in range(120):
                if ([i,j]) in p:
                    rew[i,j] = -1
                elif ([i,j]) in q:
                    rew[i,j] = -2
                elif([i,j]) in r:
                    rew[i,j] = -3
                elif([i,j]) in s:
                    rew[i,j] = 10
                elif([i,j]) in t:
                    rew[i,j] = 1
                else:
                    rew[i,j] = 0
        
        plt.imshow(rew)
        plt.show()   
 
   
   
   
   
  
   

   
   
   
   
   
   
   

   
   
   
   
   
   
   
   
   
   
   
 
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
 
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
