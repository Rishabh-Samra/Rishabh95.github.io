{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from skimage import io, transform\n",
    "from skimage.io import imread\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/rishabh/Char_Dataset\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/home/rishabh/Char_Dataset/training/A/*.jpg\"\n",
    "file1 = glob.glob(path1)\n",
    "a1 = []\n",
    "for i in file1:\n",
    "    a = imread(i)\n",
    "    a1.append(a)\n",
    "print(\"***1***\")\n",
    "# path2 = \"/home/rishabh/Char_Dataset/training/E/*.jpg\"\n",
    "# file2 = glob.glob(path2)\n",
    "# a2 = []\n",
    "# for j in file2:\n",
    "#     a = imread(j)\n",
    "#     a2.append(a)\n",
    "# print(\"***2***\")\n",
    "path3 = \"/home/rishabh/Char_Dataset/training/F/*.jpg\"\n",
    "file3 = glob.glob(path3)\n",
    "a3 = []\n",
    "for k in file3:\n",
    "    a = imread(k)\n",
    "    a3.append(a)\n",
    "print(\"***3***\")\n",
    "path4 = \"/home/rishabh/Char_Dataset/training/H/*.jpg\"\n",
    "file4 = glob.glob(path4)\n",
    "a4 = []\n",
    "for l in file4:\n",
    "    a = imread(l)\n",
    "    a4.append(a)\n",
    "print(\"***4***\")\n",
    "\n",
    "# path5 = \"/home/rishabh/Char_Dataset/training/I/*.jpg\"\n",
    "# file5 = glob.glob(path5)\n",
    "# a5 = []\n",
    "# for l in file4:\n",
    "#     a = imread(l)\n",
    "#     a5.append(a)\n",
    "    \n",
    "# print(\"***5***\")\n",
    "\n",
    "path6 = \"/home/rishabh/Char_Dataset/training/L/*.jpg\"\n",
    "file6 = glob.glob(path6)\n",
    "a6 = []\n",
    "for l in file6:\n",
    "    a = imread(l)\n",
    "    a6.append(a)\n",
    "print(\"***6***\")\n",
    "\n",
    "    \n",
    "# path7 = \"/home/rishabh/Char_Dataset/training/M/*.jpg\"\n",
    "# file7 = glob.glob(path4)\n",
    "# a7 = []\n",
    "# for l in file7:\n",
    "#     a = imread(l)\n",
    "#     a7.append(a)\n",
    "    \n",
    "# print(\"***7***\")\n",
    "\n",
    "path8 = \"/home/rishabh/Char_Dataset/training/N/*.jpg\"\n",
    "file8 = glob.glob(path8)\n",
    "a8 = []\n",
    "for l in file8:\n",
    "    a = imread(l)\n",
    "    a8.append(a)   \n",
    "    \n",
    "print(\"***8***\")\n",
    "\n",
    "path9 = \"/home/rishabh/Char_Dataset/training/T/*.jpg\"\n",
    "file9 = glob.glob(path9)\n",
    "a9 = []\n",
    "for l in file9:\n",
    "    a = imread(l)\n",
    "    a9.append(a)\n",
    "    \n",
    "print(\"***9***\")\n",
    "\n",
    "p0 = \"/home/rishabh/Char_Dataset/training/X/*.jpg\"\n",
    "f0 = glob.glob(p0)\n",
    "a0 = []\n",
    "for l in f0:\n",
    "    a = imread(l)\n",
    "    a0.append(a)\n",
    "    \n",
    "print(\"***10***\")\n",
    "\n",
    "    \n",
    "images = np.concatenate((a1,a3,a4,a6,a8,a9,a0),axis = 0).astype('float32')\n",
    "#images = torch.tensor(images)\n",
    "#images = images.permute(0,3,1,2)\n",
    "#images = Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(6000)\n",
    "b = np.ones(6000)\n",
    "c = np.ones(6000)*2\n",
    "d = np.ones(6000)*3\n",
    "e = np.ones(6000)*4\n",
    "f = np.ones(6000)*5\n",
    "g = np.ones(6000)*6\n",
    "# h = np.ones(6000)*7\n",
    "# i = np.ones(6000)*8\n",
    "# j = np.ones(6000)*9\n",
    "labels = np.concatenate((a,b,c,d,e,f,g), axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa0 = \"/home/rishabh/Char_Dataset/validation/A/*.jpg\"\n",
    "fa0 = glob.glob(pa0)\n",
    "A0 = []\n",
    "for l in fa0:\n",
    "    A = imread(l)\n",
    "    A0.append(A)\n",
    "    \n",
    "# P1 = \"/home/rishabh/Char_Dataset/validation/E/*.jpg\"\n",
    "# f1 = glob.glob(P1)\n",
    "# A1 = []\n",
    "# for l in f1:\n",
    "#     A = imread(l)\n",
    "#     A1.append(A)\n",
    "\n",
    "P2 = \"/home/rishabh/Char_Dataset/validation/F/*.jpg\"\n",
    "f2 = glob.glob(P2)\n",
    "A2 = []\n",
    "for l in f2:\n",
    "    A = imread(l)\n",
    "    A2.append(A)\n",
    "    \n",
    "P3 = \"/home/rishabh/Char_Dataset/validation/H/*.jpg\"\n",
    "f3 = glob.glob(P3)\n",
    "A3 = []\n",
    "for l in f3:\n",
    "    A = imread(l)\n",
    "    A3.append(A)\n",
    "\n",
    "\n",
    "# P4 = \"/home/rishabh/Char_Dataset/validation/I/*.jpg\"\n",
    "# f4 = glob.glob(P4)\n",
    "# A4 = []\n",
    "# for l in f4:\n",
    "#     A = imread(l)\n",
    "#     A4.append(A)\n",
    "\n",
    "P5 = \"/home/rishabh/Char_Dataset/validation/L/*.jpg\"\n",
    "f5 = glob.glob(P5)\n",
    "A5 = []\n",
    "for l in f5:\n",
    "    A = imread(l)\n",
    "    A5.append(A)\n",
    "\n",
    "# P6 = \"/home/rishabh/Char_Dataset/validation/M/*.jpg\"\n",
    "# f6 = glob.glob(P6)\n",
    "# A6 = []\n",
    "# for l in f6:\n",
    "#     A = imread(l)\n",
    "#     A6.append(A)\n",
    "\n",
    "P7 = \"/home/rishabh/Char_Dataset/validation/N/*.jpg\"\n",
    "f7 = glob.glob(P7)\n",
    "A7 = []\n",
    "for l in f7:\n",
    "    A = imread(l)\n",
    "    A7.append(A)\n",
    "    \n",
    "P8 = \"/home/rishabh/Char_Dataset/validation/T/*.jpg\"\n",
    "f8 = glob.glob(P8)\n",
    "A8 = []\n",
    "for l in f8:\n",
    "    A = imread(l)\n",
    "    A8.append(A)\n",
    "\n",
    "P9 = \"/home/rishabh/Char_Dataset/validation/X/*.jpg\"\n",
    "f9 = glob.glob(P9)\n",
    "A9 = []\n",
    "for l in f9:\n",
    "    A = imread(l)\n",
    "    A9.append(A)\n",
    "\n",
    "imgV = np.concatenate((A0,A2,A3,A5,A7,A8,A9), axis = 0).astype('float32')   #400x32x32x3\n",
    "#imgV = Image.fromarray(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Az = np.zeros(1001)\n",
    "B = np.ones(1001)\n",
    "C = np.ones(1001)*2\n",
    "D = np.ones(1001)*3\n",
    "E = np.ones(1001)*4\n",
    "Fa = np.ones(1001)*5\n",
    "G = np.ones(1001)*6\n",
    "# H = np.ones(1001)*7\n",
    "# I = np.ones(1001)*8\n",
    "# J = np.ones(1001)*9\n",
    "\n",
    "labV = np.concatenate((Az,B,C,D,E,Fa,G), axis= 0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['images'], sample['labels']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'images': torch.from_numpy(image),\n",
    "                'labels': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ds(Dataset):\n",
    "    def __init__(self, images, labels, transform = None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        #image = img.transpose((2,0,1))\n",
    "        # sample = {'images': image,'labels':label }\n",
    "        \n",
    "        \n",
    "        \n",
    "       # print(image.dtype)\n",
    "#         if self.transform:\n",
    "#             img = torch.from_numpy(img)\n",
    "#             sample = {'images':self.transform(img),'labels':label}  \n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ds(images,labels, transform = transform)\n",
    "testset = ds(imgV, labV, transform = transform)\n",
    "#print(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n",
    "                                        shuffle= True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = iter(trainloader).next()\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.conv3 = nn.Conv2d(20, 30, kernel_size=3)\n",
    "        self.conv4 = nn.Conv2d(30, 40, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(160, 84)\n",
    "        self.fc2 = nn.Linear(84, 42)\n",
    "        self.fc3 = nn.Linear(42,7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))  #14,10\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))  #10,20\n",
    "        x = F.relu(self.conv3_drop(self.conv3(x)))  #3,30\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x), 2)))  #3,30\n",
    "        x = x.view(-1, 160)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x1 = self.fc3(x)\n",
    "        _,ind = torch.max(x1,1) \n",
    "        return x1,ind\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 10, kernel_size=5)   \n",
    "#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  \n",
    "#         self.conv2_drop = nn.Dropout2d()\n",
    "#         self.conv3 = nn.Conv2d(20, 30, kernel_size=5)\n",
    "#         self.fc1 = nn.Linear(270, 120)\n",
    "#         #self.fc2 = nn.Linear(200, 120)\n",
    "#         self.fc2 = nn.Linear(120,84)\n",
    "#         self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(self.conv2_drop(self.conv2(x)))  #10,20\n",
    "#         x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "#         x = x.view(-1, 270)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         #x = F.relu(self.fc3(x))\n",
    "#         x1 = self.fc3(x)\n",
    "#         _,ind = torch.max(x1,1) \n",
    "#         return x1,ind\n",
    "# net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = []\n",
    "Vil = []\n",
    "acc = []\n",
    "Vacc = []\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    iter_loss = 0    \n",
    "    print('*******epoch:',epoch)\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels = data\n",
    "#         inputs = Variable(inputs)\n",
    "#         labels = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        #print('i',inputs.shape)\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        #inputs = inputs.transpose((1,0,2,3))\n",
    "        #print('f',inputs.shape)\n",
    "        outputs,ind = net(inputs)\n",
    "        #print('o',outputs.shape)\n",
    "        labels=labels.long()\n",
    "#         print('o',outputs.shape)\n",
    "#         print('l',labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        l2_reg = None                   #regularization\n",
    "        for w in net.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = w.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + w.norm(2)\n",
    "        loss += 0.05 * l2_reg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (ind == labels).float().sum()\n",
    "        running_loss += loss.item()\n",
    "        iter_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 50 mini-batches\n",
    "            print('[%d, %5d] trainng loss: %.3f' %(epoch + 1, i + 1, running_loss/200))\n",
    "            running_loss = 0.0\n",
    "    il.append((iter_loss/len(trainset)))   #training it_loss\n",
    "    TrAccuracy = 100 * correct / len(trainset)\n",
    "    print('Accuracy: %.3f' %(TrAccuracy))\n",
    "    acc.append(TrAccuracy)\n",
    "            \n",
    "    \n",
    "    Vit_loss = 0.0\n",
    "    cor = 0\n",
    "    for j,dat in enumerate(testloader,0):\n",
    "        ip,lb = dat\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        ip = ip.unsqueeze(1)\n",
    "        op,indi = net(ip)\n",
    "        lb=lb.long()\n",
    "\n",
    "        loss = criterion(op, lb)\n",
    "\n",
    "        cor += (indi == lb).float().sum()\n",
    "        Vit_loss += loss.item()\n",
    "#         if j % 100 == 99:    # print every 100 mini-batches\n",
    "#             print('[%d, %5d] ' %(epoch + 1, j + 1))\n",
    "#             running_loss = 0.0\n",
    "    Vil.append(Vit_loss/len(testset))  #validation it_loss\n",
    "    accuracy = 100 * cor / len(testset)\n",
    "    print('Validation Accuracy: %.3f' %(accuracy))\n",
    "    Vacc.append(accuracy)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "op= op.detach().numpy()\n",
    "oup = np.argmax(op, axis=1)\n",
    "lb = lb.detach().numpy()\n",
    "print('labels',lb.shape)\n",
    "cm = confusion_matrix(lb,oup)\n",
    "print(cm)\n",
    "plt.imshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(),'/home/rishabh/TransferLearning/Models/Char_simple1/3_30.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(1,20,20)\n",
    "plt.plot(x,il,label = 'Training Loss')\n",
    "plt.plot(x,Vil,label = 'Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('TrainingLoss')\n",
    "plt.legend()\n",
    "#plt.savefig('/home/rishabh/TransferLearning/simple1/7.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(x,acc,label = 'Training Accuracy')\n",
    "plt.plot(x,Vacc,label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "#plt.savefig('/home/rishabh/TransferLearning/simple1/New2_accuracy_lr0.01_20.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('3SimpleTrLoss.txt',il)\n",
    "# np.savetxt('3SimpleValLoss.txt',Vil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
